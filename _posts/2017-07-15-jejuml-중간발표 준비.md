---
layout: post
title: Jeju ML 중간 발표 준비
categories: Machine Learning
tag: ml
---

## 중간 발표 준비

#### 개요
제주는 지금 탄소없는 섬 제주 프로젝트를 진행하고 있다.
그만큼 신재생에너지에 대한 관심이 커지는 것을 알 수 있다.

#### 무엇을 구현할 것인가?
그래서 나는 신재생에너지 생산량 예측과 관련된 프로젝트를 진행해보기로 했다.
제주대학교의 태양열 판넬을 가지고 축전된 데이터로 얼만큼의 전기 에너지가 생성되는지 예측할 수 있는 전기 생산량 예측 모델을 구현하는 것을 목표로 하고 있습니다.

#### 어떻게 구현할 것인가?
LSTM을 이용해서 구현을 할 것이다.
단지 LSTM을 이용해서 구현을 한다고 하면 어떤의미가 있을까?
나의 경우에는 시계열의 데이터 셋이 있어서 LSTM을 사용하기로 했고
LSTM을 이용한 모델은 하이퍼 파라미터를 튜닝하면서 지금 현재 가지고 있는 데이터 셋에서 만들어 낼 수 있는 가장 좋은 모델을 만들어 보는 것이라고 생각한다.

#### 내가 생각하는 모델 만들기는 다음과 같다
데이터 셋 준비
베이스 라인 모델 만들기
학습시키기
필요에 따라 데이터 가공
튜닝 더 하이퍼 파라미터
결과값 보기
학습시키기
튜닝 더 하이퍼 파라미터
필요에 따라 모델 변경
학습시키기
결과값 보기 … etc 가장 좋은 성능을 내는 모델을 찾을 때 까지 연구는 계속 될 것 같다.

#### Data set
2년어치의 데이터를 가지고 있다.
데이터를 가지고 처리하는 것이 제일 중요한 것 같다.
데이터를 가공하는 방법
그냥 다 넣기
가공

#### Tuning the hyper parameters
Learning rate
The number of layer
Batch size
Hidden layer
책의 예제나 동영상들을 보면 모델이 뿅 나오고 좋은 결과를 예측해내고 잘 학습할 수 있는 하이퍼 파라미터들을 소개해준다. 그래서 처음에 나는 아 그냥 저대로 하면 되는구나.. 라고 생각을 했는데
그것은 오해였다.
데이터 마다 그리고 그 데이터를 어떻게 가공했느냐에 따라 그리고 모델을 어떻게 구성했느냐에 따라 설정해줘야하는 하이퍼 파라미터들이 있었다.
머신러닝에서 좋은 모델을 얻기 위한 키는 ‘하이퍼 파라미터’라고 생각한다.
여기에는 저와 같이 머신러닝에 관심이 있고 예제를 돌려봤는데 정작 자신이 직접 만들어본 모델은 없는 사람들이 있을 것이라고 생각되어진다.

What does it mean?
Learning rate high —> ~~~
The number of layer high —> ~~~
Batch size and epoch high —> ~~~
Hidden layer high —> ~~~
내 결과 표를 가지고 말해보면 각 각의 속성값들에 따라 변하는 값들이 있었다.
모델의 목표는 learning rate를 이용하여 optimal한 loss value를 찾는 것에 있다.
그러면 그 신경망은 우리는 잘 학습되었다라고 말을 할 것이고
그 신경망은 잘 학습이 되었으니 좋은 결과를 나타낼 수 있을 것이다.

현재까지 찾아낸 가장 퍼포먼스가 좋은 모델은 다음과 같다.


#### 내가 풀어나가야 할 문제점
loss가 낮은데 rmse가 높은 경우는 어떤 경우일 수 있을까?
이 말인 즉슨 학습은 잘 되었는데 최종 테스트 데이터로 예측을 해보았을 때는 예측을 잘 못했다는 말이 된다. 그러면 데이터를 의심해봐야한다. 예를 들어, 작년에는 여름에 태풍도 많이오고 비도 많이 내렸다면 이번 년도에는 마른 가뭄이 오고 비도 많이 오지 않은 경우를 들 수 있고 다른 예로는 주식 투자에서 주식 예측 모델이 학습을 잘 했다고 해도 실제 테스트에서는 잘 예측을 하지 못할 수 있다. 예측할 때의 데이터가 학습할 때의 데이터와 많이 다를 경우 그럴 수 있다.
아니면 오버피팅아닌가? 내가 학습을 잘 했고 학습한 건 잘 예측하는데 다른건 꽝인 거..

#### 오버피팅 문제..
레이어를 많이쌓는다고 무조건 좋은 것은 아니더라
레이어를 쌓기위해서는 오버피팅 문제를 조심해야하는 것을 알았다.
overfitting일 가능성이 높다.
overfitting을 하면 average만을 찾을 가능성이 높기 때문에..


향후 계획

## 교수님 코멘트

데이터는 비슷한 디스트리뷰션을 가지고있어야하는데
비슷하지 못한 디스트리뷰션을 가지고있다면 학습은 잘 할 수 있는데 밸리데이션에서 안될 수도 잇다.
그래서 rmse가 낮게 나온 듯 하다.
지금 그냥 총 데이터중에 앞에 70%는 학습 뒤에 30%는 테스트로 사용하고있는데 테스트 데이터가 앞의 학습 데이터의 대표성을 갖고있지 못해서 생기는 문제라고 할 수 있다.

거의 연구가 없다.
다른 한 논문을 보면 거기서는 그렇게 했는데
나는 이렇게 해보고 있다.

데이터를 줄인 이유는 데이터를 전부 넣어서 학습을 시켰을 때는 잘 학습을 하는데
데이터를 줄이면 학습 시간은 매우 줄어들면서도 비슷한 학습 정도를 보이는 가에 대해 해보기 위해서 데이터를 줄여서 다루어 봤다.

결과가 잘 안나오는 버전, 결과가 보통인 버전, 결과가 잘 나오는 버전으로 데이터를 나눠서
버전을 나눠서 장, 단점을 적어놓을 필요가 있다.

줄어드는 폭이 작으면 epoch을 결정할 것이다.
epoch이 크면 loss가 줄어드는 것은 확인을 했다.
Learning rate는 0.01일 때가 가장 학습을 잘하는 것을 확인했다.
Learning rate가 0.1일 때는 loss가 줄어들다가 발산하는 것을 볼 수 있는데 이건 학습률이 너무 커서 그런 것 같다.
