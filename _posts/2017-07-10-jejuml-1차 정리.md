---
layout: post
title: Jeju ML 1차 정리
categories: MachineLearning
tag: ml
---

## 교수님이랑 정리한 거

신경망 평가는 loss로 최종 평가는 rmse로
loss는 weight가 변함에 따라 loss가 어떻게 변하는지 보여주는 지표로써 신경망을 평가할 때, 이 신경망이 학습이 잘 되었는지 안되었는지를 평가할 수 있는 지표이다.<br>
loss가 0에 가까워지는 것은 가장 최선의 방법이지만 다양한 데이터 셋에서는 0에 가까워지게 학습하는 것이 불가능할 수 있다 예를 들어서 그릇 모양의 loss function이 그래프에서 높이가 띄어져 있으면 미분 값은 0일지라도 높이 값이 loss값이 되기 때문에 0이 안될 수 있다. 즉 잘 학습해도 loss값이 높게 나올 수 있다는 말이다.<br>

rmse는 원래의 타겟 값과 우리가 학습시킨 모델이 예측한 값을 비교한 결과물이다.<br>

그래서 신경망을 평가할 때는 loss가 낮게 나오면 학습이 잘 되었다고 할 수 있고
학습을 완료한 후에 테스트를 할 때 rmse가 낮게 나오면 예측, 최종결과물도 잘 나왔다고 할 수 있다.<br>

그래프를 만들 때 하나의 모델에서 learning rate를 서로 다르게 한 후에 나오는 loss들을 한 그래프에 모아두면 직관적으로 보기가 편할 것이니 그래프를 만들 때 이렇게 만들 것!!!<br>

optimal한 학습률은  가장 좋은 학습률을 말하는데 하나의 모델에서 여러개의 learning rate를 설정해서 학습시켜보고 그 중에서 가장 좋은 learning rate를 뽑아서 해당 learning rate 를 기준으로 layer를 바꿔가면서 학습률을 비교하는 방법이 있을 수 있다.<br>

loss가 낮은데 rmse가 높은 경우는 어떤 경우일 수 있을까?<br>
이 말인 즉슨 학습은 잘 되었는데 최종 테스트 데이터로 예측을 해보았을 때는 예측을 잘 못했다는 말이 된다. 그러면 데이터를 의심해봐야한다. 예를 들어, 작년에는 여름에 태풍도 많이오고 비도 많이 내렸다면 이번 년도에는 마른 가뭄이 오고 비도 많이 오지 않은 경우를 들 수 있고 다른 예로는 주식 투자에서 주식 예측 모델이 학습을 잘 했다고 해도 실제 테스트에서는 잘 예측을 하지 못할 수 있다. 예측할 때의 데이터가 학습할 때의 데이터와 많이 다를 경우 그럴 수 있다.<br>
아니면 오버피팅아닌가? 내가 학습을 잘 했고 학습한 건 잘 예측하는데 다른건 꽝인 거..<br>

상관관계를 떠나서 학습을 다 시켜보았는데 loss는 줄어들고 rmse가 상승하는 케이스는 어떤 것들이 있을까? 위의 경우랑 같은 경우인 것 같다.<br>
데이터는 비슷한 디스트리뷰션을 가지고있어야하는데<br>
비슷하지 못한 디스트리뷰션을 가지고있다면 학습은 잘 할 수 있는데 밸리데이션에서 안될 수도 있다.<br>
테리 엄태웅님 블로그에서 봤다.
